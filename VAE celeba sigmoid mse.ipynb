{"cells":[{"cell_type":"markdown","metadata":{"id":"UEBilEjLj5wY"},"source":["STAT 453: Deep Learning (Spring 2021)  \n","Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n","\n","Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n","GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"fNSpQwnD_1pl"},"source":["# Convolutional Variational Autoencoder for CelebA Face Images"]},{"cell_type":"markdown","metadata":{"id":"MkoGLH_Tj5wn"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ORj09gnrj5wp"},"outputs":[],"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"hKCcQkUL_1pt"},"source":["#### Import utility functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqVq0jZ3_1pu"},"outputs":[],"source":["from helper_data import get_dataloaders_EUROSAT\n","from helper_data import UnNormalize\n","from helper_train import train_vae_v1\n","from helper_data import compute_average_faces\n","from helper_utils import set_deterministic, set_all_seeds\n","from helper_plotting import plot_accuracy, plot_training_loss\n","from helper_plotting import plot_generated_images\n","from helper_plotting import plot_latent_space_with_labels\n","from helper_plotting import plot_images_sampled_from_vae\n","from helper_plotting import plot_modified_faces\n","from helper_plotting import avgimg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":373,"status":"ok","timestamp":1668032612204,"user":{"displayName":"Aniketh Reddy","userId":"07306145381594467094"},"user_tz":300},"id":"NnT0sZIwj5wu","outputId":"2e519bd0-8bb9-4cec-a9cc-d6c40f80a5f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda:0\n"]}],"source":["##########################\n","### SETTINGS\n","##########################\n","\n","# Device\n","CUDA_DEVICE_NUM = 0\n","DEVICE = torch.device(f'cuda:{CUDA_DEVICE_NUM}' if torch.cuda.is_available() else 'cpu')\n","print('Device:', DEVICE)\n","\n","# Hyperparameters\n","RANDOM_SEED = 123\n","LEARNING_RATE = 0.0005\n","BATCH_SIZE = 256\n","NUM_EPOCHS = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvZfeSr-_1px"},"outputs":[],"source":["set_deterministic\n","set_all_seeds(RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{"id":"O2WbzmEy_1py"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFQpSZyQ_1pz"},"outputs":[],"source":["##########################\n","### Dataset\n","##########################\n","\n","\n","custom_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.CenterCrop((128, 128)),\n","    torchvision.transforms.ToTensor(),\n","    #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","\n","train_loader, valid_loader, test_loader = get_dataloaders_EUROSAT(\n","    batch_size=BATCH_SIZE,\n","    train_transforms=custom_transforms,\n","    test_transforms=custom_transforms,\n","    num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWCr6bff_1p1","executionInfo":{"status":"ok","timestamp":1668032636038,"user_tz":300,"elapsed":1051,"user":{"displayName":"Aniketh Reddy","userId":"07306145381594467094"}},"outputId":"84fee614-df36-4745-e4dd-85ec3a401368"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Set:\n","\n","Image batch dimensions: torch.Size([256, 3, 128, 128])\n","Image label dimensions: torch.Size([256])\n","\n","Validation Set:\n","Image batch dimensions: torch.Size([256, 3, 128, 128])\n","Image label dimensions: torch.Size([256])\n","\n","Testing Set:\n","Image batch dimensions: torch.Size([256, 3, 128, 128])\n","Image label dimensions: torch.Size([256])\n"]}],"source":["# Checking the dataset\n","print('Training Set:\\n')\n","for images, labels in train_loader:  \n","    print('Image batch dimensions:', images.size())\n","    print('Image label dimensions:', labels.size())\n","    #print(labels[:10])\n","    break\n","    \n","# Checking the dataset\n","print('\\nValidation Set:')\n","for images, labels in valid_loader:  \n","    print('Image batch dimensions:', images.size())\n","    print('Image label dimensions:', labels.size())\n","    #print(labels[:10])\n","    break\n","\n","# Checking the dataset\n","print('\\nTesting Set:')\n","for images, labels in test_loader:  \n","    print('Image batch dimensions:', images.size())\n","    print('Image label dimensions:', labels.size())\n","    #print(labels[:10])\n","    break\n","  \n"]},{"cell_type":"markdown","metadata":{"id":"kcF2y8_h_1p3"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJla9Nd1_1p4"},"outputs":[],"source":["##########################\n","### MODEL\n","##########################\n","\n","\n","class Reshape(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","        self.shape = args\n","\n","    def forward(self, x):\n","        return x.view(self.shape)\n","\n","\n","class Trim(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x[:, :, :128, :128]\n","\n","\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.encoder = nn.Sequential(\n","                nn.Conv2d(3, 32, stride=2, kernel_size=3, bias=False, padding=1),\n","                nn.BatchNorm2d(32),\n","                nn.LeakyReLU(0.1, inplace=True),\n","                nn.Dropout2d(0.25),\n","                #\n","                nn.Conv2d(32, 64, stride=2, kernel_size=3, bias=False, padding=1),\n","                nn.BatchNorm2d(64),\n","                nn.LeakyReLU(0.1, inplace=True),\n","                nn.Dropout2d(0.25),\n","                #\n","                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n","                nn.BatchNorm2d(64),\n","                nn.LeakyReLU(0.1, inplace=True),\n","                nn.Dropout2d(0.25),\n","                #\n","                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n","                nn.BatchNorm2d(64),\n","                nn.LeakyReLU(0.1, inplace=True),\n","                nn.Dropout2d(0.25),\n","                #\n","                nn.Flatten(),\n","        )    \n","        \n","        self.z_mean = torch.nn.Linear(4096, 200)\n","        self.z_log_var = torch.nn.Linear(4096, 200)\n","        \n","        self.decoder = nn.Sequential(\n","                torch.nn.Linear(200, 4096),\n","                Reshape(-1, 64, 8, 8),\n","                #\n","                nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3),\n","                nn.BatchNorm2d(64),\n","                nn.LeakyReLU(0.1, inplace=True),\n","                nn.Dropout2d(0.25),\n","                #\n","                nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(64),\n","                nn.LeakyReLU(0.1, inplace=True),\n","                nn.Dropout2d(0.25),\n","                #\n","                nn.ConvTranspose2d(64, 32, stride=2, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(32),\n","                nn.LeakyReLU(0.1, inplace=True),\n","                nn.Dropout2d(0.25),\n","                #\n","                nn.ConvTranspose2d(32, 3, stride=2, kernel_size=3, padding=1),\n","                #\n","                Trim(),  # 3x129x129 -> 3x128x128\n","                nn.Sigmoid()\n","                )\n","\n","\n","    def encoding_fn(self, x):\n","        x = self.encoder(x)\n","        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n","        encoded = self.reparameterize(z_mean, z_log_var)\n","        return encoded\n","\n","        \n","    def reparameterize(self, z_mu, z_log_var):\n","        eps = torch.randn(z_mu.size(0), z_mu.size(1)).to(z_mu.get_device())\n","        z = z_mu + eps * torch.exp(z_log_var/2.) \n","        return z\n","        \n","    def forward(self, x):\n","        x = self.encoder(x)\n","        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n","        encoded = self.reparameterize(z_mean, z_log_var)\n","        decoded = self.decoder(encoded)\n","        return encoded, z_mean, z_log_var, decoded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lza9t_uj5w1"},"outputs":[],"source":["set_all_seeds(RANDOM_SEED)\n","\n","model = VAE()\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "]},{"cell_type":"markdown","metadata":{"id":"RAodboScj5w6"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dzh3ROmRj5w7","outputId":"c2a79735-c631-48a2-f353-e816d9b4d244"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001/050 | Batch 0000/0071 | Loss: 12098.6973\n","Epoch: 001/050 | Batch 0050/0071 | Loss: 5233.5513\n","Time elapsed: 0.20 min\n","Epoch: 002/050 | Batch 0000/0071 | Loss: 3635.3120\n","Epoch: 002/050 | Batch 0050/0071 | Loss: 1620.4177\n","Time elapsed: 0.37 min\n","Epoch: 003/050 | Batch 0000/0071 | Loss: 1293.1393\n","Epoch: 003/050 | Batch 0050/0071 | Loss: 828.9100\n","Time elapsed: 0.55 min\n","Epoch: 004/050 | Batch 0000/0071 | Loss: 681.2802\n","Epoch: 004/050 | Batch 0050/0071 | Loss: 519.8446\n","Time elapsed: 0.72 min\n","Epoch: 005/050 | Batch 0000/0071 | Loss: 467.9373\n","Epoch: 005/050 | Batch 0050/0071 | Loss: 389.4711\n","Time elapsed: 0.91 min\n","Epoch: 006/050 | Batch 0000/0071 | Loss: 368.0197\n","Epoch: 006/050 | Batch 0050/0071 | Loss: 327.3836\n","Time elapsed: 1.09 min\n","Epoch: 007/050 | Batch 0000/0071 | Loss: 304.9360\n","Epoch: 007/050 | Batch 0050/0071 | Loss: 280.7606\n","Time elapsed: 1.27 min\n","Epoch: 008/050 | Batch 0000/0071 | Loss: 281.4113\n","Epoch: 008/050 | Batch 0050/0071 | Loss: 241.4261\n","Time elapsed: 1.44 min\n","Epoch: 009/050 | Batch 0000/0071 | Loss: 247.7614\n","Epoch: 009/050 | Batch 0050/0071 | Loss: 249.7389\n","Time elapsed: 1.61 min\n","Epoch: 010/050 | Batch 0000/0071 | Loss: 213.4654\n","Epoch: 010/050 | Batch 0050/0071 | Loss: 221.9878\n","Time elapsed: 1.78 min\n","Epoch: 011/050 | Batch 0000/0071 | Loss: 216.9597\n","Epoch: 011/050 | Batch 0050/0071 | Loss: 204.1960\n","Time elapsed: 1.96 min\n","Epoch: 012/050 | Batch 0000/0071 | Loss: 203.9758\n","Epoch: 012/050 | Batch 0050/0071 | Loss: 176.7496\n","Time elapsed: 2.13 min\n","Epoch: 013/050 | Batch 0000/0071 | Loss: 185.6587\n","Epoch: 013/050 | Batch 0050/0071 | Loss: 186.7066\n","Time elapsed: 2.31 min\n","Epoch: 014/050 | Batch 0000/0071 | Loss: 174.8871\n","Epoch: 014/050 | Batch 0050/0071 | Loss: 160.6636\n","Time elapsed: 2.48 min\n","Epoch: 015/050 | Batch 0000/0071 | Loss: 168.8284\n","Epoch: 015/050 | Batch 0050/0071 | Loss: 164.5820\n","Time elapsed: 2.65 min\n","Epoch: 016/050 | Batch 0000/0071 | Loss: 168.4380\n","Epoch: 016/050 | Batch 0050/0071 | Loss: 157.7891\n","Time elapsed: 2.82 min\n","Epoch: 017/050 | Batch 0000/0071 | Loss: 156.2955\n","Epoch: 017/050 | Batch 0050/0071 | Loss: 157.5693\n","Time elapsed: 3.00 min\n","Epoch: 018/050 | Batch 0000/0071 | Loss: 147.6466\n","Epoch: 018/050 | Batch 0050/0071 | Loss: 154.1030\n","Time elapsed: 3.17 min\n","Epoch: 019/050 | Batch 0000/0071 | Loss: 154.9163\n","Epoch: 019/050 | Batch 0050/0071 | Loss: 144.7482\n","Time elapsed: 3.35 min\n","Epoch: 020/050 | Batch 0000/0071 | Loss: 147.9390\n","Epoch: 020/050 | Batch 0050/0071 | Loss: 152.3647\n","Time elapsed: 3.52 min\n","Epoch: 021/050 | Batch 0000/0071 | Loss: 140.9956\n","Epoch: 021/050 | Batch 0050/0071 | Loss: 147.1312\n","Time elapsed: 3.69 min\n","Epoch: 022/050 | Batch 0000/0071 | Loss: 136.8372\n","Epoch: 022/050 | Batch 0050/0071 | Loss: 143.8430\n","Time elapsed: 3.87 min\n","Epoch: 023/050 | Batch 0000/0071 | Loss: 137.0043\n","Epoch: 023/050 | Batch 0050/0071 | Loss: 134.5688\n","Time elapsed: 4.04 min\n","Epoch: 024/050 | Batch 0000/0071 | Loss: 136.1074\n","Epoch: 024/050 | Batch 0050/0071 | Loss: 128.2725\n","Time elapsed: 4.21 min\n","Epoch: 025/050 | Batch 0000/0071 | Loss: 127.0798\n","Epoch: 025/050 | Batch 0050/0071 | Loss: 131.7651\n","Time elapsed: 4.39 min\n","Epoch: 026/050 | Batch 0000/0071 | Loss: 122.4024\n","Epoch: 026/050 | Batch 0050/0071 | Loss: 131.9171\n","Time elapsed: 4.56 min\n","Epoch: 027/050 | Batch 0000/0071 | Loss: 138.4912\n","Epoch: 027/050 | Batch 0050/0071 | Loss: 127.0573\n","Time elapsed: 4.73 min\n","Epoch: 028/050 | Batch 0000/0071 | Loss: 133.0730\n","Epoch: 028/050 | Batch 0050/0071 | Loss: 121.1964\n","Time elapsed: 4.90 min\n","Epoch: 029/050 | Batch 0000/0071 | Loss: 138.5282\n","Epoch: 029/050 | Batch 0050/0071 | Loss: 120.4408\n","Time elapsed: 5.08 min\n","Epoch: 030/050 | Batch 0000/0071 | Loss: 120.3928\n","Epoch: 030/050 | Batch 0050/0071 | Loss: 123.3986\n","Time elapsed: 5.25 min\n","Epoch: 031/050 | Batch 0000/0071 | Loss: 130.2972\n","Epoch: 031/050 | Batch 0050/0071 | Loss: 121.0404\n","Time elapsed: 5.42 min\n","Epoch: 032/050 | Batch 0000/0071 | Loss: 121.7387\n","Epoch: 032/050 | Batch 0050/0071 | Loss: 117.0994\n","Time elapsed: 5.59 min\n","Epoch: 033/050 | Batch 0000/0071 | Loss: 120.9938\n","Epoch: 033/050 | Batch 0050/0071 | Loss: 116.2221\n","Time elapsed: 5.76 min\n","Epoch: 034/050 | Batch 0000/0071 | Loss: 112.0324\n","Epoch: 034/050 | Batch 0050/0071 | Loss: 116.3179\n","Time elapsed: 5.94 min\n","Epoch: 035/050 | Batch 0000/0071 | Loss: 124.5962\n","Epoch: 035/050 | Batch 0050/0071 | Loss: 121.8658\n","Time elapsed: 6.11 min\n","Epoch: 036/050 | Batch 0000/0071 | Loss: 110.5975\n","Epoch: 036/050 | Batch 0050/0071 | Loss: 128.7573\n","Time elapsed: 6.29 min\n","Epoch: 037/050 | Batch 0000/0071 | Loss: 117.1662\n","Epoch: 037/050 | Batch 0050/0071 | Loss: 104.9521\n","Time elapsed: 6.46 min\n","Epoch: 038/050 | Batch 0000/0071 | Loss: 113.6184\n","Epoch: 038/050 | Batch 0050/0071 | Loss: 120.0785\n","Time elapsed: 6.63 min\n","Epoch: 039/050 | Batch 0000/0071 | Loss: 119.9108\n"]}],"source":["log_dict = train_vae_v1(num_epochs=NUM_EPOCHS, model=model, \n","                        optimizer=optimizer, device=DEVICE, \n","                        train_loader=train_loader,\n","                        skip_epoch_stats=True,\n","                        logging_interval=50,\n","                        save_model='vae_celeba_02.pt')"]},{"cell_type":"markdown","metadata":{"id":"RiQdaaDt_1p-"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIiyo_4M_1p_"},"outputs":[],"source":["plot_training_loss(log_dict['train_reconstruction_loss_per_batch'], NUM_EPOCHS, custom_label=\" (reconstruction)\")\n","plot_training_loss(log_dict['train_kl_loss_per_batch'], NUM_EPOCHS, custom_label=\" (KL)\")\n","plot_training_loss(log_dict['train_combined_loss_per_batch'], NUM_EPOCHS, custom_label=\" (combined)\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGscwOrm_1qA"},"outputs":[],"source":["#unnormalizer = UnNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","plot_generated_images(data_loader=train_loader,\n","                      model=model,\n","                      #unnormalizer=unnormalizer,\n","                      device=DEVICE,\n","                      modeltype='VAE')           "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atg54eZd_1qB"},"outputs":[],"source":["for i in range(10):\n","    plot_images_sampled_from_vae(model=model, device=DEVICE, latent_size=200)\n","    plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"uQjF7to1EbSY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avg_img_with_forest, avg_img_without_forest = compute_average_faces(\n","    feature_idx=2,\n","    image_dim=200,\n","    data_loader=train_loader,\n","    device=DEVICE,\n","    encoding_fn=model.encoding_fn)"],"metadata":{"id":"C6XTGQdZ7cKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avg_img_with_industrial, avg_img_without_industrial = compute_average_faces(\n","    feature_idx=5, # smiling\n","    image_dim=200,\n","    data_loader=train_loader,\n","    device=DEVICE,\n","    encoding_fn=model.encoding_fn)"],"metadata":{"id":"4uE3OX-uENUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(2, 2))\n","ax.imshow(model.decoder(avg_img_with_forest.to(DEVICE)).squeeze().to('cpu').detach().permute(1,2,0))\n","plt.show()"],"metadata":{"id":"N_XjCCWkEQXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(2, 2))\n","ax.imshow(model.decoder(avg_img_with_industrial.to(DEVICE)).squeeze().to('cpu').detach().permute(1,2,0))\n","plt.show()"],"metadata":{"id":"idgKHlynES-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rmWHK7J7EZaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EXAMPLE_IMAGE = images[1]\n","diff = (avg_img_with_forest - avg_img_with_industrial)\n","\n","example_img = EXAMPLE_IMAGE.unsqueeze(0).to(DEVICE)\n","with torch.no_grad():\n","    encoded = model.encoding_fn(example_img).squeeze(0).to('cpu')\n","\n","plot_modified_faces(original=encoded,\n","                    decoding_fn=model.decoder,\n","                    device=DEVICE,\n","                    diff=diff)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Lx4iW36bEU9M"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"toc":{"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"371px"},"toc_section_display":true,"toc_window_display":true},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}